digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<excellent &le; 0.189<br/>entropy = 0.999<br/>samples = 12715<br/>value = [6601, 6114]<br/>class = positive>, fillcolor="#fdf6f0"] ;
1 [label=<good &le; 0.206<br/>entropy = 0.999<br/>samples = 11624<br/>value = [5588, 6036]<br/>class = nagative>, fillcolor="#f0f8fd"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<great &le; 0.169<br/>entropy = 0.981<br/>samples = 9581<br/>value = [4014, 5567]<br/>class = nagative>, fillcolor="#c8e4f8"] ;
1 -> 2 ;
3 [label=<location &le; 0.143<br/>entropy = 0.952<br/>samples = 8538<br/>value = [3171, 5367]<br/>class = nagative>, fillcolor="#aed7f4"] ;
2 -> 3 ;
4 [label=<delicious &le; 0.265<br/>entropy = 0.934<br/>samples = 8193<br/>value = [2865, 5328]<br/>class = nagative>, fillcolor="#a3d2f3"] ;
3 -> 4 ;
5 [label=<amazing &le; 0.086<br/>entropy = 0.919<br/>samples = 7965<br/>value = [2658, 5307]<br/>class = nagative>, fillcolor="#9ccef2"] ;
4 -> 5 ;
6 [label=<lovely &le; 0.304<br/>entropy = 0.903<br/>samples = 7762<br/>value = [2471, 5291]<br/>class = nagative>, fillcolor="#95cbf1"] ;
5 -> 6 ;
7 [label=<poor &le; 0.077<br/>entropy = 0.884<br/>samples = 7533<br/>value = [2274, 5259]<br/>class = nagative>, fillcolor="#8fc7f0"] ;
6 -> 7 ;
8 [label=<entropy = 0.902<br/>samples = 7141<br/>value = [2267, 4874]<br/>class = nagative>, fillcolor="#95cbf1"] ;
7 -> 8 ;
9 [label=<entropy = 0.129<br/>samples = 392<br/>value = [7, 385]<br/>class = nagative>, fillcolor="#3d9fe5"] ;
7 -> 9 ;
10 [label=<hot &le; 0.304<br/>entropy = 0.584<br/>samples = 229<br/>value = [197, 32]<br/>class = positive>, fillcolor="#e99559"] ;
6 -> 10 ;
11 [label=<entropy = 0.536<br/>samples = 221<br/>value = [194, 27]<br/>class = positive>, fillcolor="#e99355"] ;
10 -> 11 ;
12 [label=<entropy = 0.954<br/>samples = 8<br/>value = [3, 5]<br/>class = nagative>, fillcolor="#b0d8f5"] ;
10 -> 12 ;
13 [label=<breakfast &le; 0.17<br/>entropy = 0.398<br/>samples = 203<br/>value = [187, 16]<br/>class = positive>, fillcolor="#e78c4a"] ;
5 -> 13 ;
14 [label=<quite &le; 0.289<br/>entropy = 0.247<br/>samples = 171<br/>value = [164, 7]<br/>class = positive>, fillcolor="#e68641"] ;
13 -> 14 ;
15 [label=<entropy = 0.22<br/>samples = 170<br/>value = [164, 6]<br/>class = positive>, fillcolor="#e68640"] ;
14 -> 15 ;
16 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
14 -> 16 ;
17 [label=<breakfast &le; 0.178<br/>entropy = 0.857<br/>samples = 32<br/>value = [23, 9]<br/>class = positive>, fillcolor="#efb286"] ;
13 -> 17 ;
18 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = nagative>, fillcolor="#399de5"] ;
17 -> 18 ;
19 [label=<entropy = 0.784<br/>samples = 30<br/>value = [23, 7]<br/>class = positive>, fillcolor="#eda775"] ;
17 -> 19 ;
20 [label=<however &le; 0.183<br/>entropy = 0.443<br/>samples = 228<br/>value = [207, 21]<br/>class = positive>, fillcolor="#e88e4d"] ;
4 -> 20 ;
21 [label=<would &le; 0.202<br/>entropy = 0.388<br/>samples = 224<br/>value = [207, 17]<br/>class = positive>, fillcolor="#e78b49"] ;
20 -> 21 ;
22 [label=<although &le; 0.216<br/>entropy = 0.325<br/>samples = 219<br/>value = [206, 13]<br/>class = positive>, fillcolor="#e78945"] ;
21 -> 22 ;
23 [label=<entropy = 0.27<br/>samples = 216<br/>value = [206, 10]<br/>class = positive>, fillcolor="#e68743"] ;
22 -> 23 ;
24 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
22 -> 24 ;
25 [label=<go &le; 0.274<br/>entropy = 0.722<br/>samples = 5<br/>value = [1, 4]<br/>class = nagative>, fillcolor="#6ab6ec"] ;
21 -> 25 ;
26 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = nagative>, fillcolor="#399de5"] ;
25 -> 26 ;
27 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
25 -> 27 ;
28 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = nagative>, fillcolor="#399de5"] ;
20 -> 28 ;
29 [label=<breakfast &le; 0.226<br/>entropy = 0.509<br/>samples = 345<br/>value = [306, 39]<br/>class = positive>, fillcolor="#e89152"] ;
3 -> 29 ;
30 [label=<available &le; 0.276<br/>entropy = 0.411<br/>samples = 327<br/>value = [300, 27]<br/>class = positive>, fillcolor="#e78c4b"] ;
29 -> 30 ;
31 [label=<area &le; 0.356<br/>entropy = 0.381<br/>samples = 324<br/>value = [300, 24]<br/>class = positive>, fillcolor="#e78b49"] ;
30 -> 31 ;
32 [label=<choice &le; 0.281<br/>entropy = 0.34<br/>samples = 317<br/>value = [297, 20]<br/>class = positive>, fillcolor="#e78946"] ;
31 -> 32 ;
33 [label=<entropy = 0.316<br/>samples = 315<br/>value = [297, 18]<br/>class = positive>, fillcolor="#e78945"] ;
32 -> 33 ;
34 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = nagative>, fillcolor="#399de5"] ;
32 -> 34 ;
35 [label=<drink &le; 0.175<br/>entropy = 0.985<br/>samples = 7<br/>value = [3, 4]<br/>class = nagative>, fillcolor="#cee6f8"] ;
31 -> 35 ;
36 [label=<entropy = 0.811<br/>samples = 4<br/>value = [3, 1]<br/>class = positive>, fillcolor="#eeab7b"] ;
35 -> 36 ;
37 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
35 -> 37 ;
38 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
30 -> 38 ;
39 [label=<quality &le; 0.22<br/>entropy = 0.918<br/>samples = 18<br/>value = [6, 12]<br/>class = nagative>, fillcolor="#9ccef2"] ;
29 -> 39 ;
40 [label=<staff &le; 0.284<br/>entropy = 0.811<br/>samples = 16<br/>value = [4, 12]<br/>class = nagative>, fillcolor="#7bbeee"] ;
39 -> 40 ;
41 [label=<clean &le; 0.358<br/>entropy = 0.592<br/>samples = 14<br/>value = [2, 12]<br/>class = nagative>, fillcolor="#5aade9"] ;
40 -> 41 ;
42 [label=<entropy = 0.391<br/>samples = 13<br/>value = [1, 12]<br/>class = nagative>, fillcolor="#49a5e7"] ;
41 -> 42 ;
43 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
41 -> 43 ;
44 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = positive>, fillcolor="#e58139"] ;
40 -> 44 ;
45 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = positive>, fillcolor="#e58139"] ;
39 -> 45 ;
46 [label=<staff &le; 0.206<br/>entropy = 0.705<br/>samples = 1043<br/>value = [843, 200]<br/>class = positive>, fillcolor="#eb9f68"] ;
2 -> 46 ;
47 [label=<location &le; 0.279<br/>entropy = 0.788<br/>samples = 826<br/>value = [631, 195]<br/>class = positive>, fillcolor="#eda876"] ;
46 -> 47 ;
48 [label=<expensive &le; 0.294<br/>entropy = 0.827<br/>samples = 750<br/>value = [555, 195]<br/>class = positive>, fillcolor="#eead7f"] ;
47 -> 48 ;
49 [label=<quality &le; 0.299<br/>entropy = 0.809<br/>samples = 736<br/>value = [553, 183]<br/>class = positive>, fillcolor="#eeab7b"] ;
48 -> 49 ;
50 [label=<hot &le; 0.275<br/>entropy = 0.786<br/>samples = 711<br/>value = [544, 167]<br/>class = positive>, fillcolor="#eda876"] ;
49 -> 50 ;
51 [label=<entropy = 0.764<br/>samples = 688<br/>value = [535, 153]<br/>class = positive>, fillcolor="#eca572"] ;
50 -> 51 ;
52 [label=<entropy = 0.966<br/>samples = 23<br/>value = [9, 14]<br/>class = nagative>, fillcolor="#b8dcf6"] ;
50 -> 52 ;
53 [label=<breakfast &le; 0.234<br/>entropy = 0.943<br/>samples = 25<br/>value = [9, 16]<br/>class = nagative>, fillcolor="#a8d4f4"] ;
49 -> 53 ;
54 [label=<entropy = 0.998<br/>samples = 17<br/>value = [8, 9]<br/>class = nagative>, fillcolor="#e9f4fc"] ;
53 -> 54 ;
55 [label=<entropy = 0.544<br/>samples = 8<br/>value = [1, 7]<br/>class = nagative>, fillcolor="#55abe9"] ;
53 -> 55 ;
56 [label=<night &le; 0.199<br/>entropy = 0.592<br/>samples = 14<br/>value = [2, 12]<br/>class = nagative>, fillcolor="#5aade9"] ;
48 -> 56 ;
57 [label=<though &le; 0.362<br/>entropy = 0.391<br/>samples = 13<br/>value = [1, 12]<br/>class = nagative>, fillcolor="#49a5e7"] ;
56 -> 57 ;
58 [label=<entropy = 0.0<br/>samples = 12<br/>value = [0, 12]<br/>class = nagative>, fillcolor="#399de5"] ;
57 -> 58 ;
59 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
57 -> 59 ;
60 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
56 -> 60 ;
61 [label=<entropy = 0.0<br/>samples = 76<br/>value = [76, 0]<br/>class = positive>, fillcolor="#e58139"] ;
47 -> 61 ;
62 [label=<fresh &le; 0.471<br/>entropy = 0.158<br/>samples = 217<br/>value = [212, 5]<br/>class = positive>, fillcolor="#e6843e"] ;
46 -> 62 ;
63 [label=<night &le; 0.492<br/>entropy = 0.133<br/>samples = 216<br/>value = [212, 4]<br/>class = positive>, fillcolor="#e5833d"] ;
62 -> 63 ;
64 [label=<small &le; 0.195<br/>entropy = 0.106<br/>samples = 215<br/>value = [212, 3]<br/>class = positive>, fillcolor="#e5833c"] ;
63 -> 64 ;
65 [label=<table &le; 0.552<br/>entropy = 0.076<br/>samples = 214<br/>value = [212, 2]<br/>class = positive>, fillcolor="#e5823b"] ;
64 -> 65 ;
66 [label=<entropy = 0.043<br/>samples = 213<br/>value = [212, 1]<br/>class = positive>, fillcolor="#e5823a"] ;
65 -> 66 ;
67 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
65 -> 67 ;
68 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
64 -> 68 ;
69 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
63 -> 69 ;
70 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
62 -> 70 ;
71 [label=<friendly &le; 0.298<br/>entropy = 0.777<br/>samples = 2043<br/>value = [1574, 469]<br/>class = positive>, fillcolor="#eda774"] ;
1 -> 71 ;
72 [label=<good &le; 0.323<br/>entropy = 0.807<br/>samples = 1872<br/>value = [1409, 463]<br/>class = positive>, fillcolor="#eeaa7a"] ;
71 -> 72 ;
73 [label=<location &le; 0.302<br/>entropy = 0.932<br/>samples = 688<br/>value = [449, 239]<br/>class = positive>, fillcolor="#f3c4a2"] ;
72 -> 73 ;
74 [label=<bit &le; 0.115<br/>entropy = 0.953<br/>samples = 641<br/>value = [402, 239]<br/>class = positive>, fillcolor="#f4ccaf"] ;
73 -> 74 ;
75 [label=<however &le; 0.483<br/>entropy = 0.94<br/>samples = 623<br/>value = [401, 222]<br/>class = positive>, fillcolor="#f3c7a7"] ;
74 -> 75 ;
76 [label=<could &le; 0.39<br/>entropy = 0.928<br/>samples = 611<br/>value = [401, 210]<br/>class = positive>, fillcolor="#f3c3a1"] ;
75 -> 76 ;
77 [label=<entropy = 0.917<br/>samples = 600<br/>value = [401, 199]<br/>class = positive>, fillcolor="#f2c09b"] ;
76 -> 77 ;
78 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 11]<br/>class = nagative>, fillcolor="#399de5"] ;
76 -> 78 ;
79 [label=<entropy = 0.0<br/>samples = 12<br/>value = [0, 12]<br/>class = nagative>, fillcolor="#399de5"] ;
75 -> 79 ;
80 [label=<room &le; 0.278<br/>entropy = 0.31<br/>samples = 18<br/>value = [1, 17]<br/>class = nagative>, fillcolor="#45a3e7"] ;
74 -> 80 ;
81 [label=<entropy = 0.0<br/>samples = 17<br/>value = [0, 17]<br/>class = nagative>, fillcolor="#399de5"] ;
80 -> 81 ;
82 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
80 -> 82 ;
83 [label=<entropy = 0.0<br/>samples = 47<br/>value = [47, 0]<br/>class = positive>, fillcolor="#e58139"] ;
73 -> 83 ;
84 [label=<expensive &le; 0.561<br/>entropy = 0.7<br/>samples = 1184<br/>value = [960, 224]<br/>class = positive>, fillcolor="#eb9e67"] ;
72 -> 84 ;
85 [label=<would &le; 0.174<br/>entropy = 0.684<br/>samples = 1167<br/>value = [955, 212]<br/>class = positive>, fillcolor="#eb9d65"] ;
84 -> 85 ;
86 [label=<though &le; 0.689<br/>entropy = 0.676<br/>samples = 1162<br/>value = [955, 207]<br/>class = positive>, fillcolor="#eb9c64"] ;
85 -> 86 ;
87 [label=<dinner &le; 0.167<br/>entropy = 0.668<br/>samples = 1157<br/>value = [955, 202]<br/>class = positive>, fillcolor="#ea9c63"] ;
86 -> 87 ;
88 [label=<entropy = 0.656<br/>samples = 1146<br/>value = [952, 194]<br/>class = positive>, fillcolor="#ea9b61"] ;
87 -> 88 ;
89 [label=<entropy = 0.845<br/>samples = 11<br/>value = [3, 8]<br/>class = nagative>, fillcolor="#83c2ef"] ;
87 -> 89 ;
90 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = nagative>, fillcolor="#399de5"] ;
86 -> 90 ;
91 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = nagative>, fillcolor="#399de5"] ;
85 -> 91 ;
92 [label=<good &le; 0.476<br/>entropy = 0.874<br/>samples = 17<br/>value = [5, 12]<br/>class = nagative>, fillcolor="#8bc6f0"] ;
84 -> 92 ;
93 [label=<breakfast &le; 0.165<br/>entropy = 0.722<br/>samples = 15<br/>value = [3, 12]<br/>class = nagative>, fillcolor="#6ab6ec"] ;
92 -> 93 ;
94 [label=<ate &le; 0.369<br/>entropy = 0.414<br/>samples = 12<br/>value = [1, 11]<br/>class = nagative>, fillcolor="#4ba6e7"] ;
93 -> 94 ;
95 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 11]<br/>class = nagative>, fillcolor="#399de5"] ;
94 -> 95 ;
96 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
94 -> 96 ;
97 [label=<available &le; 0.321<br/>entropy = 0.918<br/>samples = 3<br/>value = [2, 1]<br/>class = positive>, fillcolor="#f2c09c"] ;
93 -> 97 ;
98 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = positive>, fillcolor="#e58139"] ;
97 -> 98 ;
99 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
97 -> 99 ;
100 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = positive>, fillcolor="#e58139"] ;
92 -> 100 ;
101 [label=<expensive &le; 0.235<br/>entropy = 0.219<br/>samples = 171<br/>value = [165, 6]<br/>class = positive>, fillcolor="#e68640"] ;
71 -> 101 ;
102 [label=<experience &le; 0.575<br/>entropy = 0.191<br/>samples = 170<br/>value = [165, 5]<br/>class = positive>, fillcolor="#e6853f"] ;
101 -> 102 ;
103 [label=<better &le; 0.511<br/>entropy = 0.162<br/>samples = 169<br/>value = [165, 4]<br/>class = positive>, fillcolor="#e6843e"] ;
102 -> 103 ;
104 [label=<guest &le; 0.31<br/>entropy = 0.129<br/>samples = 168<br/>value = [165, 3]<br/>class = positive>, fillcolor="#e5833d"] ;
103 -> 104 ;
105 [label=<staff &le; 0.092<br/>entropy = 0.094<br/>samples = 167<br/>value = [165, 2]<br/>class = positive>, fillcolor="#e5833b"] ;
104 -> 105 ;
106 [label=<entropy = 0.544<br/>samples = 16<br/>value = [14, 2]<br/>class = positive>, fillcolor="#e99355"] ;
105 -> 106 ;
107 [label=<entropy = 0.0<br/>samples = 151<br/>value = [151, 0]<br/>class = positive>, fillcolor="#e58139"] ;
105 -> 107 ;
108 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
104 -> 108 ;
109 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
103 -> 109 ;
110 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
102 -> 110 ;
111 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = nagative>, fillcolor="#399de5"] ;
101 -> 111 ;
112 [label=<however &le; 0.18<br/>entropy = 0.371<br/>samples = 1091<br/>value = [1013, 78]<br/>class = positive>, fillcolor="#e78b48"] ;
0 -> 112 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
113 [label=<expensive &le; 0.358<br/>entropy = 0.353<br/>samples = 1083<br/>value = [1011, 72]<br/>class = positive>, fillcolor="#e78a47"] ;
112 -> 113 ;
114 [label=<pricey &le; 0.296<br/>entropy = 0.337<br/>samples = 1075<br/>value = [1008, 67]<br/>class = positive>, fillcolor="#e78946"] ;
113 -> 114 ;
115 [label=<slow &le; 0.196<br/>entropy = 0.326<br/>samples = 1072<br/>value = [1008, 64]<br/>class = positive>, fillcolor="#e78946"] ;
114 -> 115 ;
116 [label=<disappointing &le; 0.211<br/>entropy = 0.316<br/>samples = 1069<br/>value = [1008, 61]<br/>class = positive>, fillcolor="#e78945"] ;
115 -> 116 ;
117 [label=<although &le; 0.374<br/>entropy = 0.305<br/>samples = 1065<br/>value = [1007, 58]<br/>class = positive>, fillcolor="#e68844"] ;
116 -> 117 ;
118 [label=<poor &le; 0.185<br/>entropy = 0.291<br/>samples = 1056<br/>value = [1002, 54]<br/>class = positive>, fillcolor="#e68844"] ;
117 -> 118 ;
119 [label=<entropy = 0.284<br/>samples = 1054<br/>value = [1002, 52]<br/>class = positive>, fillcolor="#e68843"] ;
118 -> 119 ;
120 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = nagative>, fillcolor="#399de5"] ;
118 -> 120 ;
121 [label=<excellent &le; 0.275<br/>entropy = 0.991<br/>samples = 9<br/>value = [5, 4]<br/>class = positive>, fillcolor="#fae6d7"] ;
117 -> 121 ;
122 [label=<entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = nagative>, fillcolor="#7bbeee"] ;
121 -> 122 ;
123 [label=<entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = positive>, fillcolor="#eca06a"] ;
121 -> 123 ;
124 [label=<selection &le; 0.165<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = nagative>, fillcolor="#7bbeee"] ;
116 -> 124 ;
125 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
124 -> 125 ;
126 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
124 -> 126 ;
127 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
115 -> 127 ;
128 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
114 -> 128 ;
129 [label=<excellent &le; 0.3<br/>entropy = 0.954<br/>samples = 8<br/>value = [3, 5]<br/>class = nagative>, fillcolor="#b0d8f5"] ;
113 -> 129 ;
130 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = nagative>, fillcolor="#399de5"] ;
129 -> 130 ;
131 [label=<excellent &le; 0.426<br/>entropy = 1.0<br/>samples = 6<br/>value = [3, 3]<br/>class = positive>, fillcolor="#ffffff"] ;
129 -> 131 ;
132 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = positive>, fillcolor="#e58139"] ;
131 -> 132 ;
133 [label=<staff &le; 0.21<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = nagative>, fillcolor="#7bbeee"] ;
131 -> 133 ;
134 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = nagative>, fillcolor="#399de5"] ;
133 -> 134 ;
135 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = positive>, fillcolor="#e58139"] ;
133 -> 135 ;
136 [label=<service &le; 0.126<br/>entropy = 0.811<br/>samples = 8<br/>value = [2, 6]<br/>class = nagative>, fillcolor="#7bbeee"] ;
112 -> 136 ;
137 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6]<br/>class = nagative>, fillcolor="#399de5"] ;
136 -> 137 ;
138 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = positive>, fillcolor="#e58139"] ;
136 -> 138 ;
}